<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Handling Effective Date and Expiry Date with DMN Decisions</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/cICXoGpO-pA/handling-effective-date-and-expiry-date-with-dmn-decisions.html" /><author><name>Sadhana Nandakumar</name></author><id>https://blog.kie.org/2021/09/handling-effective-date-and-expiry-date-with-dmn-decisions.html</id><updated>2021-09-27T14:04:56Z</updated><content type="html">DMN is a modeling language and notation for the precise specification of business decisions. DMN is easily readable by the different types of people involved in decision management. supports the DMN open standards.  Handling effective date and expiry date of decisions is a common requirement across businesses. While it is entirely possible to handle the validity of decisions with different versions of the decision model, oftentimes there is a requirement to add variation at an individual decision node.  In this article, we will show how to achieve that with a practical example. Let us assume that we have a Card Approval Decision as shown below As you can see, we are calculating the Card Score based on Annual Income and Assets. This then determines if an Automatic Approval can be performed.  The Standard card score decision is expressed as a Decision Table: Let us say we now want a new condition for row 1, “When Annual Income &lt; 50 and Assets &lt; 100” starting with a specific date. Red Hat Process Automation Manager supports built-in functions to make this possible. today()Current Datenow()Current Date Time Let us now modify this decision table to add the date expiry condition. Notice how we have added the date condition to the decision row to decide it should be fired.  Let us now run these changes using the . The DMN artifact from this example is available .  Notice that since the effective date for Condition “When Annual Income &lt; 50 and Assets &lt; 100” matches the first row, the card Score evaluates to 312. Let us now change the rule to be effective from the beginning of this year and see what happens. You can now see that the rule matched the second row based on the date condition. Another way to define date validity is by defining it as a decision node so that one or more decisions can make use of it, it also allows you to make sure the logic is confined to one place. We will now use a combination of the built in date functions(today()/now()), as well as theto make this possible. Let us now create a new decision node called Date Validity.  Notice how we are using the temporal built-in function “after” in conjunction with “today” to determine validity. Now we will add this node to the existing DMN. The Standard card score now uses the Date Validity as defined by the decision node earlier. Let us now run this DMN. The DMN artifact from this example is available .  Since the effective date for the decision was next year, row 2 was fired yielding the card score result of 350. Test scenarios in Red Hat Process Automation Manager enable you to validate the functionality of business rules and business rule data before deploying them into a production environment. With a test scenario, you use data from your project to set given conditions and expected results based on one or more defined business rules. It is important to note that, while the test scenario by default maps the input data to the condition columns, it is possible to add a decision point as a condition column for better testability.  For instance, in the following scenario, you can see that Date Validity, which is a decision node in the DMN, is also pulled in as a condition column. If there needs to be a granular control of date checks, the decision node can be split up to reference date as an input column too. Now we can reference Today with different dates to test edge conditions seamlessly. References: – "Red Hat Decision Manager Supported Standards": * KIE Live 24: Squeezing the most out of DMN features, by . The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/cICXoGpO-pA" height="1" width="1" alt=""/&gt;</content><dc:creator>Sadhana Nandakumar</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/handling-effective-date-and-expiry-date-with-dmn-decisions.html</feedburner:origLink></entry><entry><title>Four reasons developers should use Ansible</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gV-jNmtU-0Y/four-reasons-developers-should-use-ansible" /><author><name>Don Schenck</name></author><id>34c398d7-20c8-478f-b887-418e086e3d55</id><updated>2021-09-27T07:00:00Z</updated><published>2021-09-27T07:00:00Z</published><summary type="html">&lt;p&gt;Ansible is described as "simple IT automation." It's an agentless tool, meaning you don't have to install anything on the systems you are controlling. With Ansible, you can install software, configure system settings and features, and do all the things system administrators do. You know, the "operations" side of the team.&lt;/p&gt; &lt;p&gt;So why should you, a developer, care? You should. Let me explain.&lt;/p&gt; &lt;h2&gt;What does Ansible do?&lt;/h2&gt; &lt;p&gt;To put it in the simplest terms, Ansible lets you do things remotely that you would otherwise do at the command line. Specifically, it's used to install software and change system settings. It puts a machine into the state in which you want it to remain and keeps it there.&lt;/p&gt; &lt;p&gt;For example, you can install (and maintain) a given version of a library on a select group of servers across your organization. You might want &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; 3.8 on all your &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; machines running in AWS. Ansible is perfect for that.&lt;/p&gt; &lt;p&gt;Maybe you want to make sure version 2 of your own software is installed on those servers. Again, Ansible does that.&lt;/p&gt; &lt;p&gt;You can even do nifty things like perform a rolling update across your virtual machines (VMs). Remove some of the servers from the load balancer pool, update to version 3 of your software (using our example), and return the servers to the load balancer pool. Then move on to the next batch of servers, and so on, until all of your servers are running version 3 of your application.&lt;/p&gt; &lt;h2&gt;How Ansible can help developers&lt;/h2&gt; &lt;p&gt;Ansible is a big deal for developers because you can easily configure and maintain machines with what Ansible calls "playbooks": easy-to-read, declarative statements that you can store in source control. Take a look at this example (copied from the &lt;a href="https://www.ansible.com/blog/getting-started-writing-your-first-playbook"&gt;Ansible Getting Started page&lt;/a&gt;) and you'll be able to mostly figure out what it does:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;--- - name: Install nginx hosts: host.name.ip become: true tasks: - name: Add epel-release repo yum: name: epel-release state: present - name: Install nginx yum: name: nginx state: present - name: Insert Index Page template: src: index.html dest: /usr/share/nginx/html/index.html - name: Start NGiNX service: name: nginx state: started&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I can think of four reasons why you, as a developer, should care about Ansible:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;You can use it to set up small environments.&lt;/li&gt; &lt;li&gt;You can use it to make sure the correct prerequisites are installed.&lt;/li&gt; &lt;li&gt;You can be a catalyst for real DevOps culture at work.&lt;/li&gt; &lt;li&gt;You can use it for yourself.&lt;/li&gt; &lt;/ol&gt;&lt;h3&gt;1: You can use Ansible to set up small environments&lt;/h3&gt; &lt;p&gt;Throughout my many years in enterprise software development, my colleagues and I often had the opportunity to carve out small networks of our own. We used these networks to install various packages and software, test different approaches, try new things... in short, play around.&lt;/p&gt; &lt;p&gt;Having Ansible on hand to create environments quickly is fantastic. It's often desirable to set things up, experiment, then tear everything down and start over. Nothing is more frustrating than deploying a solution and having it fail with the "But it runs on our machines" experience, only because an artifact on your machine wasn't included in the installation process. Ansible can solve that by easily enabling you to start from zero every time.&lt;/p&gt; &lt;p&gt;As a developer, I love the idea of completely starting over every time—as long as it is super easy. Thanks, Ansible.&lt;/p&gt; &lt;h3&gt;2: You can use Ansible to make sure the correct prerequisites are installed&lt;/h3&gt; &lt;p&gt;Sometimes breaking changes to libraries or runtimes (Python, anyone?) can, well, break your application. Because Ansible playbooks are easy to understand and change—it's YAML, after all—you can enforce the correct version of any library, runtime, software, etc. This relieves operations from this burden, which plays perfectly into my next point.&lt;/p&gt; &lt;h3&gt;3: You can be a catalyst for real DevOps culture at work&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/devops/"&gt;DevOps&lt;/a&gt; is a culture and set of behaviors. It's not a spreadsheet or a piece of software you install. It's developers and operations working together to automate all the things. Having &lt;a href="https://www.redhat.com/en/topics/automation/what-is-infrastructure-as-code-iac"&gt;Infrastructure as Code&lt;/a&gt; is the basis. Allowing developers and operations to change that code, use version control, and trust one another—well, that's about as DevOps-y as you can get. The ability to pull down an Ansible playbook, run it, and test the results any time you want? That's huge. It is programming and system administration as one.&lt;/p&gt; &lt;h3&gt;4: You can use Ansible for yourself&lt;/h3&gt; &lt;p&gt;What if you were working on your laptop and you wanted to wipe it clean and start over? What if you could wipe it clean, pull a playbook from a network drive (or GitHub or a thumb drive or what-have-you), and use a tool to set up your machine?&lt;/p&gt; &lt;p&gt;With Ansible, you can do this over and over with the same results. You can repave your machine whenever you want without having to remember to run a script at the command line or install this and that.&lt;/p&gt; &lt;p&gt;In fact, as a developer, this might be your best use of Ansible and a great starting point for mastering it.&lt;/p&gt; &lt;h2&gt;Ops, I did it again&lt;/h2&gt; &lt;p&gt;So there it is. The old "DevOps" word again. We developers need to embrace it because it's not going away. Let's use this DevOps concept to everyone's advantage and promote cross-disciplinary skills, more Infrastructure as Code, and the ultimate goal: more stable systems. Something we all want.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/27/four-reasons-developers-should-use-ansible" title="Four reasons developers should use Ansible"&gt;Four reasons developers should use Ansible&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gV-jNmtU-0Y" height="1" width="1" alt=""/&gt;</summary><dc:creator>Don Schenck</dc:creator><dc:date>2021-09-27T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/27/four-reasons-developers-should-use-ansible</feedburner:origLink></entry><entry><title type="html">Beginners Guide to Installing Process Automation Tooling in a Local Container using Podman</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Rcwp8fHMwJo/beginners-guide-to-rhpam-local-conainter-podman.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/eaXnZhtViS0/beginners-guide-to-rhpam-local-conainter-podman.html</id><updated>2021-09-27T05:00:00Z</updated><content type="html">Recently the open source  announced that there was solid support for using its container tooling to replace docker on your local development machine. Ring in the joyous music and off we go to explore how we can get back to basics without the issues of licensing around the developer desktop container tooling. Note, the rest of this tutorial will be based on the current version of Podman at the time of publication, v3.3.1. The first thing you want to do is just install the Podman tooling, which is fairly painless using BREW: $ brew install podman Now you are ready to kick off the virtual machine with the proper settings to start doing something real, like adding developer process automation tooling to your local machine. You start by initialise and start the virtual machine to run Podman on: $ podman machine init --memory 6144 --disk-size 20 Extracting compressed file Image resized. If it's your first time doing this, an image will be downloaded first, but in this case a cached version of that image is just being unpacked and setup. Now it's time to start the virtual machine: $ podman machine start INFO[0000] waiting for clients... INFO[0000] listening tcp://0.0.0.0:7777 INFO[0000] new connection from to /var/folders/_y/1rjzwypx57sd677v9jzrr0nc0000gp/T/podman/qemu_podman-machine-default.sock Waiting for VM ... qemu-system-x86_64: warning: host doesn't support requested feature: CPUID.80000001H:ECX.svm [bit 2] Now once this completes, you're ready to take a swing at spinning up the developer process automation tooling by Red Hat. First we pull in this nice demo project for installing it locally or in a container: $ git clone https://gitlab.com/bpmworkshop/rhpam-install-demo.git Then go into the rhpam-install-demo directory and examine the instructions for using this with Podman to spin up the process automation developer tooling in a container. You will note that you need to head over to and obtain the files listed in the installs/README before you can continue.  Before you try to use Podman to build, pull, or run any images on your machine, verify that the virtual machine is running to support you: $ podman machine list NAME VM TYPE CREATED LAST UP podman-machine-default* qemu 9 minutes ago Currently running Once that's done, you can start from the root directory and build your first image: $ podman build -t rhpam-install:7.11 . ...CUT OUTPUT... STEP 24/26: USER 1000 --&gt; 2a682b0c5aa STEP 25/26: EXPOSE 9990 9999 8080 8001 --&gt; 6a1ed7c4d2e STEP 26/26: CMD ["/opt/jboss/rhpam/jboss-eap-7.3/bin/standalone.sh","-c","standalone.xml","-b", "0.0.0.0","-bmanagement","0.0.0.0"] COMMIT rhpam-install:7.11 --&gt; fbba2e41494 Successfully tagged localhost/rhpam-install:7.11 fbba2e4149409794a8c81f05c59f402e4ddca775dc07cbaeed3ae3bf0cf703b7 This will take some time to execute every line in the provided Dockerfile, so feel free to watch or explore that file until the build process is done. You can verify that you have a new image built: $ podman image list REPOSITORY TAG IMAGE ID CREATED SIZE localhost/rhpam-install 7.11 fbba2e414940 7 minutes ago 4.05 GB docker.io/jbossdemocentral/developer latest b73501ac39b1 5 years ago 514 MB You can see the base image is a customised developer image that we then use to build our rhpam-install image.  The next step is to run the image: $ podman run -dt -p 8080:8080 -p 9990:9990 rhpam-install 9bd0e70e58dd471a4ad17b87281c8bfe73a98e5a9bfc6cbd37fa98fb0198d1a0 This starts the image and spins up both Red Hat Enterprise Application Server and running inside of that the Red Hat Process Automation tooling. You can view this by looking up the container id, then viewing the log file to ensure the container startup is completed before using the tooling: $ podman container list CONTAINER ID IMAGE COMMAND CREATED 9bd0e70e58dd localhost/rhpam-install:7.11 /opt/jboss/rhpam/... 2 minutes ago $ podman logs 9bd0e70e58dd ... CUT OUTPUT OF DUMPED LOG FILE... 12:50:50,612 INFO [org.kie.workbench.common.screens.datasource.management.backend.DataSourceManagementBootstrap] (pool-30-thread-1) Initialize deployments task finished successfully. Note you can use the -f flag to attache the logs output to the console and watch the container start up. Now that it's been started successfully we can make use of the port mapping we did at podman run when we used the -p flag. Port 8080 from our localhost is now mapped through to the containers port.  You can verify this with: $ podman port 9bd0e70e58dd 8080/tcp -&gt; 0.0.0.0:8080 9990/tcp -&gt; 0.0.0.0:9990 Now you can access the process automation business central log in to access the tooling at: http://localhost:8080/business-central The login user: erics The password: redhatpam1! You will be presented with the business central dashboard and you are ready to start automating processes using this tooling in a container on your local machine.  If you need help getting started, try one of the !&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Rcwp8fHMwJo" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/eaXnZhtViS0/beginners-guide-to-rhpam-local-conainter-podman.html</feedburner:origLink></entry><entry><title>Containerized Python Flask development on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/rtyk8BnVxa0/containerized-python-flask-development-environment-red-hat-codeready-workspaces" /><author><name>Shane Boulden</name></author><id>7ca79c17-de44-4c55-82fc-b85c38f78bcf</id><updated>2021-09-24T07:00:00Z</updated><published>2021-09-24T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview/"&gt;Red Hat CodeReady Workspaces&lt;/a&gt; provides developers with containerized development environments hosted on &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. Having a hosted development environment that's pre-built for your chosen stack and customized for your project makes onboarding new developers easier because everything they need is already running in a containerized workspace.&lt;/p&gt; &lt;p&gt;In this article, I'll show you how to use CodeReady Workspaces to get up and running quickly with a Flask-based &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; project. We'll set up the environment, make a few modifications to the application, then validate and verify the changes from within the containerized development environment.&lt;/p&gt; &lt;h2&gt;Updated for OpenShift 4&lt;/h2&gt; &lt;p&gt;To follow the example in this article, you'll need &lt;a href="https://developers.redhat.com/products/openshift/whats-new"&gt;OpenShift 4&lt;/a&gt;. You can use &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt; on your Windows, macOS, or Linux laptop. Or, you can access a hosted Red Hat OpenShift Container Platform cluster for free in the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Let's get started!&lt;/p&gt; &lt;h2&gt;Deploying CodeReady Workspaces&lt;/h2&gt; &lt;p&gt;CodeReady Workspaces uses a Kubernetes Operator for deployment. A &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Kubernetes Operator&lt;/a&gt; is basically a method of packaging, deploying, and managing a Kubernetes application.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you'd like to know more about the Operator Framework, see the awesome write-up by Brandon Philips on the &lt;a href="https://blog.openshift.com/introducing-the-operator-framework/"&gt;OpenShift blog&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;CodeReady Workspaces is available through the OpenShift Operator Hub. Once you've found the CodeReady Workspaces Operator, install it as shown in Figure 1.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Installing the CodeReady Workspaces Operator." data-entity-type="file" data-entity-uuid="c2996aee-63a9-46d6-ba45-04b249c7c8b3" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2015-36-29.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 1: Installing the CodeReady Workspaces Operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Select the defaults for this installation, as shown in Figure 2.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Default configuration for the CodeReady Workspaces Operator." data-entity-type="file" data-entity-uuid="a42b9085-3e19-46fd-a906-ab42d25ea5aa" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2015-36-41.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 2: The default configuration for the CodeReady Workspaces Operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;When the CodeReady Workspaces Operator is installed and ready to use, you'll see a notification like the one in Figure 3.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The CodeReady Workspaces Operator has been successfully installed." data-entity-type="file" data-entity-uuid="3b0e1451-8f6e-4a1f-b2a7-0ff7af0fe103" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2014-33-55.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 3: The operator has been successfully installed.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Once the operator is installed, you can access it under &lt;strong&gt;Installed Operators&lt;/strong&gt;. From here, select &lt;strong&gt;Create Instance&lt;/strong&gt; next to the &lt;strong&gt;CodeReady Workspaces Cluster&lt;/strong&gt; custom resource. Accept all the defaults, and select &lt;strong&gt;Create&lt;/strong&gt;, as shown in Figure 4.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Creating an OpenShift cluster in CodeReady Workspaces." data-entity-type="file" data-entity-uuid="254f113b-edd8-4131-9bea-b55b2c001964" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2014-34-13.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 4: Creating a CodeReady Workspaces cluster with the operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The operator will now take over and create all of the components for your CodeReady Workspaces cluster. Once it's finished you'll see a couple of new routes, as shown in Figure 5.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="New routes in CodeReady Workspaces." data-entity-type="file" data-entity-uuid="29d05a2f-d016-4e7d-927d-396aa88b49a9" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2014-36-49.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 5: New routes for CodeReady Workspaces created by the operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Navigate to the CodeReady route, follow the prompts to authenticate with single sign-on (SSO), and you'll be directed to the dashboard shown in Figure 6.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The CodeReady Workspaces dashboard." data-entity-type="file" data-entity-uuid="f5f129fb-69a8-42dd-a377-ef29af175afb" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2014-56-18.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 6: The CodeReady Workspaces dashboard.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Next, we'll set up the Flask workspace for our Python project.&lt;/p&gt; &lt;h2&gt;Creating the Flask workspace&lt;/h2&gt; &lt;p&gt;We're going to use a &lt;a href="https://developers.redhat.com/blog/2019/12/09/codeready-workspaces-devfile-demystified"&gt;devfile&lt;/a&gt; to create the workspace for our application. A &lt;em&gt;devfile&lt;/em&gt; is a way of codifying a containerized workspace, and is usually stored with the application source so that it can be version-controlled alongside the application. Here is the &lt;a href="https://github.com/shaneboulden/flask-questions-app/blob/main/devfile.yml"&gt;devfile for the example Flask application&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;apiVersion: 1.0.0 metadata: generateName: flask- projects: - name: flask-app source: type: git location: "https://github.com/shaneboulden/flask-questions-app" components: - type: chePlugin id: ms-python/python/latest - type: dockerimage alias: python image: quay.io/eclipse/che-python-3.8:next memoryLimit: 512Mi mountSources: true env: - name: FLASK_SECRET value: 'you-will-never-guess' endpoints: - name: websocket-forward port: 8080 attributes: protocol: http secure: 'false' public: 'true' discoverable: 'false' commands: - name: run actions: - type: exec component: python command: '${HOME}/.local/bin/gunicorn wsgi:application -b 0.0.0.0:8080' workdir: '${CHE_PROJECTS_ROOT}/flask-app' - name: install actions: - type: exec component: python command: 'pip3 install -r requirements.txt' workdir: '${CHE_PROJECTS_ROOT}/flask-app'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Let's break down this devfile:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;New workspaces will be generated with a name starting with &lt;code&gt;flask-&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;The source code for this project is hosted at &lt;a href="https://github.com/shaneboulden/flask-questions-app"&gt;https://github.com/shaneboulden/flask-questions-app&lt;/a&gt; and will be cloned into the workspace.&lt;/li&gt; &lt;li&gt;We're using a base Python environment from the &lt;a href="https://www.eclipse.org/che/docs/che-7/hosted-che/hosted-che/"&gt;Eclipse Che&lt;/a&gt; project hosted at Quay.io.&lt;/li&gt; &lt;li&gt;We've limited workspaces created from this devfile to 512 MB of memory.&lt;/li&gt; &lt;li&gt;We've created an environment variable for the Flask cross-site request forgery (CSRF) secret, ensuring the secret isn't stored in the source.&lt;/li&gt; &lt;li&gt;We've created an endpoint for the web server used in development. This will allow us to test out the Flask app inside the containerized workspace.&lt;/li&gt; &lt;li&gt;We've created two commands, &lt;code&gt;install&lt;/code&gt; and &lt;code&gt;run&lt;/code&gt;. We'll use these to easily install the application dependencies, run the web server, and view our changes to the Flask application.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Select &lt;strong&gt;Custom Workspace&lt;/strong&gt; from the CodeReady Workspaces dashboard. Then, in the &lt;strong&gt;Devfile&lt;/strong&gt; section of the following form specify the devfile URL (Figure 7) :&lt;/p&gt; &lt;p&gt;&lt;code&gt;https://raw.githubusercontent.com/shaneboulden/flask-questions-app/main/devfile.yml &lt;/code&gt;&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Specify the devfile URL in the custom workspace configuration." data-entity-type="file" data-entity-uuid="784f3852-2450-4d7d-8ea8-5c9aaec7de79" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2016-57-53.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 7: Specify the devfile URL in the custom workspace configuration.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Select &lt;strong&gt;Load Devfile—&gt;Create &amp; Open&lt;/strong&gt; to start creating the custom workspace. When it's complete you'll see the new workspace with the source code explorer open, as shown in Figure 8.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The new custom workspace." data-entity-type="file" data-entity-uuid="e7878db2-dbe4-4206-9498-5bd96971317a" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2017-00-26.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 8: The new custom workspace for Flask.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Exploring the Flask workspace&lt;/h2&gt; &lt;p&gt;Now that our workspace is created, let's explore some of the configuration we've created. Select the power cord on the right to see the endpoints (Figure 9).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Viewing the devfile endpoints." data-entity-type="file" data-entity-uuid="49c55275-1b81-455d-950d-d16ee1156392" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2017-00-39.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 9: Viewing the devfile endpoints.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;There's a single endpoint created here for port 8080. When we run the web server inside the workspace, this endpoint will be activated so we can view the application.&lt;/p&gt; &lt;p&gt;We also have a couple of commands created by the devfile. If you select &lt;strong&gt;Terminal—&gt;Run task&lt;/strong&gt;, you'll see the commands shown in Figure 10.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="A list of available tasks in the devfile." data-entity-type="file" data-entity-uuid="612aabf2-27df-449f-9104-65f1fe32dd0a" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-37-33.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 10: A list of runnable tasks.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Let's run the &lt;strong&gt;Install&lt;/strong&gt; first. When you execute the task, you should see a terminal output window opened, as shown in Figure 11.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Output of running the Install task." data-entity-type="file" data-entity-uuid="4fc4e9f2-adc1-488e-b7db-9b3260d25d82" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-37-50.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 11: Run the Install task.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Our dependencies are now installed, so let's run the application. Select &lt;strong&gt;Terminal—&gt;Run Task&lt;/strong&gt; and the &lt;strong&gt;run&lt;/strong&gt; command. You'll see the web server open up in a new terminal output in a new window. CodeReady Workspaces will also detect that the endpoint is now available, and prompt you to either open it in a new tab or a preview within the workspace. Figure 12 shows the endpoint prompt.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Open or preview the endpoint in CodeReady Workspaces." data-entity-type="file" data-entity-uuid="93528f16-aa3d-4962-895b-2dd7470d5575" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-40-11.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 12: Open or preview the endpoint in CodeReady Workspaces.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Select either option to view the Flask application, as shown in Figure 13.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="View the Flask web application." data-entity-type="file" data-entity-uuid="321513a5-3585-474b-b3f4-b3aedfbf717a" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-40-20.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 13: Viewing the Flask web application.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Updating the Flask application&lt;/h2&gt; &lt;p&gt;Everything's looking good! We've got a containerized workspace created for our application development environment, and a couple of codified commands and endpoints we can use to quickly prepare the environment and get our application running.&lt;/p&gt; &lt;p&gt;Let's make a change and see how it is reflected in the workspace. Expand the source code explorer and find the &lt;code&gt;index.html&lt;/code&gt; file, as shown in Figure 14.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The index template in code explorer." data-entity-type="file" data-entity-uuid="434c5d23-288f-4fc2-ab5b-c5d84752c010" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-43-48.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 14: The index template in code explorer.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Change the line:&lt;/p&gt; &lt;p&gt;&lt;code&gt;&lt;h1&gt;Ask us anything.&lt;/h1&gt;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;To read:&lt;/p&gt; &lt;p&gt;&lt;code&gt;&lt;h1&gt;Welcome.&lt;/h1&gt;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Stop the web server (press &lt;strong&gt;Ctrl-C&lt;/strong&gt; in the &lt;strong&gt;Run&lt;/strong&gt; window), and select &lt;strong&gt;Terminal—&gt;Run last task&lt;/strong&gt; to restart the web server. Alternatively, you can press &lt;strong&gt;Ctrl-Shift-K&lt;/strong&gt;. Open the preview or new tab again, and verify the page now contains the new greeting shown in Figure 15.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Modified code" data-entity-type="file" data-entity-uuid="7bd9b10c-3e81-4f82-a727-cad4cf51b982" src="https://developers.redhat.com/sites/default/files/inline-images/Screenshot%20from%202021-09-12%2021-48-15.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 15: Verify the update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Do more with Python, Flask, and OpenShift&lt;/h2&gt; &lt;p&gt;We now have a containerized development environment for our Flask application that's hosted on OpenShift, and we can access it anytime. When new developers join the team, we can simply allow them to load the workspace with the devfile and quickly instantiate their own development environment. All the changes to the devfile are version controlled with the application source, so we can keep our development environment in lockstep with the Flask application.&lt;/p&gt; &lt;p&gt;If you want to take what you've learned in this article a step further, you can create a Python development environment for a machine learning workflow. Brian Nguyen's &lt;a href="https://cloud.redhat.com/blog/configure-code-ready-workspace-for-developing-machine-learning-workflow"&gt;excellent article&lt;/a&gt; will get you started. Also, see &lt;a href="https://developers.redhat.com/blog/2021/04/14/using-a-custom-devfile-registry-and-c-with-red-hat-codeready-workspaces"&gt;Using a custom devfile registry and C++ with Red Hat CodeReady Workspaces&lt;/a&gt; and &lt;a href="https://developers.redhat.com/blog/2020/11/16/devfiles-and-kubernetes-cluster-support-in-openshift-connector-0-2-0-extension-for-vs-code"&gt;Devfiles and Kubernetes cluster support in OpenShift Connector 0.2.0 extension for VS Code&lt;/a&gt; for more about the technologies used in the example. Visit the &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;CodeReady Workspaces landing page&lt;/a&gt; for more about CodeReady Workspaces.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/blog/2019/02/18/containerized-python-flask-development-environment-red-hat-codeready-workspaces" title="Containerized Python Flask development on Red Hat OpenShift"&gt;Containerized Python Flask development on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/rtyk8BnVxa0" height="1" width="1" alt=""/&gt;</summary><dc:creator>Shane Boulden</dc:creator><dc:date>2021-09-24T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/02/18/containerized-python-flask-development-environment-red-hat-codeready-workspaces</feedburner:origLink></entry><entry><title type="html">RESTEasy Announcements and Plans</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/QHB_KNfJvdE/" /><author><name /></author><id>https://resteasy.github.io/2021/09/23/announcements-and-releases/</id><updated>2021-09-23T18:11:11Z</updated><dc:creator /><summary type="html">&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/QHB_KNfJvdE" height="1" width="1" alt=""/&gt;</summary><feedburner:origLink>https://resteasy.github.io/2021/09/23/announcements-and-releases/</feedburner:origLink></entry><entry><title type="html">Introducing Kogito API Incubation</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/U1sAAZ0dDJI/kogito-api-incubation.html" /><author><name>Edoardo Vacchi</name></author><id>https://blog.kie.org/2021/09/kogito-api-incubation.html</id><updated>2021-09-23T15:00:00Z</updated><content type="html">Would you like to be able to evaluate a process in Kogito with a simple Java API like this? var id = appRoot.get(ProcessIds.class).get("hello-world"); // wrap the Map in a data context var ctx = MapDataContext.create(); ctx.set("name", "Paul"); // evaluate the process and get the result as a map-like var res = processSvc.evaluate(id, ctx).as(MapDataContext.class); System.out.println(res.get("message")); // "hello, Paul!" What about invoking a specific subcomponent of a DMN, such as a decision service ? MapDataContext ctx = MapDataContext.create(); // construct the path to a DMN decision service var id = appRoot .get(DecisionIds.class) .get("https://github.com/evacchi/my-namespace", "Traffic Violation") .services() .get("my-service-id"); // evaluate the decision and return the result var res = dmnSvc.evaluate(id, ctx); Or maybe you do not want the flexibility of a Map. Maybe you just want to use a simple data object. Is a Java record concise enough for you? public record LinearRegParams( float fld1, float fld2, String fld3) implements DataContext, DefaultCastable {} public record LinearRegResult( float fld4) implements DataContext, DefaultCastable {} // construct the path to a PMML predictive model var id = appRoot .get(PredictionIds.class) .get("LinReg"); // create the context object var ctx = new LinearRegParams(...); // evaluate var res = svc.evaluate(id, ctx); // map the result to the record var rec = pmmlSvc.as(LinearRegResult.class); What if you could just use that record in your REST endpoint? @POST @Consumes(MediaType.APPLICATION_JSON) // take the custom data context as a parameter, // get JSON conversion automatically public Float hello(LinearRegParams payload) { var id = appRoot .get(PredictionIds.class) .get("LinReg"); var res = pmmlSvc.evaluate(id, payload); // extract the float result and return it var rec = res.as(LinearRegResult.class); return rec.fld4(); } Or maybe evaluate a Drools query and get a stream of typed results? public record MyQueryResult( String contents) implements DataContext, DefaultCastable {} @POST @Produces(MediaType.APPLICATION_JSON) @Consumes(MediaType.APPLICATION_JSON) public Stream&lt;MyQueryResult&gt; hello(MapDataContext ctx) { var queryId = appRoot.get(RuleUnitIds.class) .get(Hello.class) .queries() .get("hello"); // evaluate the query return svc.evaluate(queryId, ctx) map(ctx -&gt; ctx.as(MyQueryResult.class)); // map each result to a typed value } You have learned to love the powerful Kogito codegen capabilities. You just drop your asset to your source directory (or you feed it to the powerful operator) and you get a fully-functional REST endpoint for free. However, from day one we understood that automated code-generation would bring you only to a certain point. That is why we wanted to provide a great programmatic API. Yet, so far we were not confident enough to open up the internal API that we were using as our code generation target. The reason is that we wanted to get it right first. We are now happy to release a first version of our new public API in incubation state starting from version 1.13! WHAT DOES INCUBATION MEAN? Incubation means that this API is a first approximation of what we will deliver in the end. It is made available early in the spirit of release early, release often, with no guarantees that it will not change. However, you are welcome to try it and give us feedback on it, because once released we will not be able to make any more changes to it. WHEN CAN I GET MY HANDS ON THIS? We plan to roll out a first version of this for the 1.13 release. However, until this is incubating then we will not commit to long-term stability. Breakage may occur; you have been warned: use it at your risk! WHEN ARE YOU DELIVERING THE FINAL VERSION OF THIS API ? We plan to roll this out in stages. As you know our platform contains multiple components (DMN, PMML, Processes, Severless Workflows, Drools rules), and it is possible that each one of those will reach maturity at a different moment in time. Moreover, every component has a different set of capabilities. So we may decide to roll out features instead of full components. For instance, we may declare that the API for evaluating a DMN model has reached maturity stage, but keep the listener API still in incubation. SHALL I WAIT FOR IT TO BE FINAL? Well that depends on you, really. Do you like living on the bleeding edge? If you picked Kogito we may assume that you do! Even if we make some changes, we don’t think they will be revolutionary. Indeed, you will certainly have to rename your imports from org.kie.kogito.api.incubation. to org.kie.kogito.api. at some point. Maybe update your dependencies. But the structure will probably be pretty similar to what we will deliver now. So don’t be too scared. OK, SURE BUT THIS LOOKS PRETTY VANILLA. IS THERE SOMETHING ELSE TO IT? Indeed. What if I told you that every identifier is really translated into path? // /predictions/LinReg appRoot.get(PredictionIds.class).get("LinReg"); // /rule-units/org.kie.kogito.examples.Hello/queries/hello appRoot.get(RuleUnitIds.class) .get(Hello.class) .queries() .get("hello"); // /decisions/https%3A%2F%2Fgithub.com%2Fevacchi%2Fmy-namespace%23Traffic%20Violation var id = appRoot .get(DecisionIds.class) .get("https://github.com/evacchi/my-namespace", "Traffic Violation") // /processes/hello-world var id = appRoot.get(ProcessIds.class).get("hello-world"); What if I told you that paths could be mounted onto URIs ? kogito://my-app-1@my.host1.name:54321/predictions/LinReg kogito://my-app-2@my.host2.name:54321/rule-units/org.kie.kogito.examples.Hello/queries/hello kogito://my-app-3@my.host3.name:54321/decisions/https%3A%2F%2Fgithub.com%2Fevacchi%2Fmy-namespace%23Traffic%20Violation kogito://my-app-4@my.host4.name:54321/rules/processes/hello-world What if you could use one unified way to send commands across the network between Kogito applications? What if those same IDs and commands were easily mapped onto HTTP commands? POST https://my.host1.name:54321/my-app-1/predictions/LinReg { "json" : "data" } or would you rather prefer Cloud Events ? POST https://my.host1.name:54321 { "specversion" : "1.0", "type" : "org.kie.kogito.predictions.evaluate", "source" : "/some/sender/id", "org.kie.kogito.target" : "/predictions/LinReg", "id" : "...", "time" : "2021-04-05T17:31:00Z", "datacontenttype" : "text/json", "data" : { "fld1" : 3.0, "fld2" : 2.0, "fld3" : "y" } } WAIT, ARE YOU SAYING THIS IS ALREADY AVAILABLE? THAT’S AWES– No, it’s not, sorry to burst that bubble. We are still working on it. But really, that is where we would like to end up. For now, just enjoy this new way to develop your own REST endpoints! But stay tuned: easy serialization and distribution are the main drivers of this redesign. ALRIGHT, ALRIGHT. THAT STILL LOOKS PRETTY COOL. WHERE DO I GET IT? Wait for the 1.13 release next week! You will find the examples at the usual place. But if you are curious, . OK COOL Wait, wait wouldn’t you like to learn more about how this was designed? NOT REALLY, BUT IF YOU INSIST Well I do. In the next post I’ll explain the design rationale for this API. You may also join us on October 2nd at our KIE Live; yours truly will deliver a presentation and will give a live coding demo. Ain’t that cool? The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/U1sAAZ0dDJI" height="1" width="1" alt=""/&gt;</content><dc:creator>Edoardo Vacchi</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/kogito-api-incubation.html</feedburner:origLink></entry><entry><title type="html">Infinispan 13.0.0.CR1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/F_NGFkJBBIk/infinispan-13-cr1" /><author><name>Katia Aresti</name></author><id>https://infinispan.org/blog/2021/09/23/infinispan-13-cr1</id><updated>2021-09-23T12:00:00Z</updated><content type="html">Dear Infinispan community, We’ve just released 13.0.0.CR1 which brings you several new features along with a number of enhancements and bug fixes. Here is a non-exhaustive list of Infinispan 13 has in store: MUTABLE CACHE CONFIGURATION You can now update cache configuration at runtime with the CLI. IMPROVED CLUSTER UPGRADES We’ve done quite a lot of work on rolling upgrade operations in Infinispan 13, making the process smoother from the REST API, CLI, and with our Kubernetes Operator. RE-BALANCING OPERATIONS Control cluster topology re-balancing from the REST API, CLI, and Console. PERSISTENT STORAGE IMPROVEMENTS * File-based caches stores now default to SoftIndexFileStore. * We’ve added a new SQL cache store. CROSS-SITE REPLICATION For global Infinispan clusters, this release brings a number of improvements: * Cross-site replication operations from the Console. * Additional statistics for increased observability. * Better logging details for cross-site cluster views. SIMPLIFIED SERVER CLUSTER SECURITY Infinispan Server can automatically enable SSL for the cluster transport. QUERIES * Added support for local query operations. HELM CHARTS We’ve added an Infinispan Helm chart for deploying clusters to Kubernetes. DOCUMENTATION AND TUTORIALS We’ve made a number of documentation improvements this release, including: * A new guide for Hot Rod JS clients. * Better organization and documentation for Infinispan simple tutorials. * Replaced the Integration Guide with a dedicated guide for Spring users as well as a guide for Hibernate caches. * A brand new guide for Indexing and Querying. * Overhauled and updated Configuration Guide. * Additional JSON and YAML configuration examples.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/F_NGFkJBBIk" height="1" width="1" alt=""/&gt;</content><dc:creator>Katia Aresti</dc:creator><feedburner:origLink>https://infinispan.org/blog/2021/09/23/infinispan-13-cr1</feedburner:origLink></entry><entry><title>Leader election in Kubernetes using Apache Camel</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ptZfmNY_LdI/leader-election-kubernetes-using-apache-camel" /><author><name>Stephen Nimmo</name></author><id>82cd25ad-54ed-445f-a5b5-85e2b1f9259f</id><updated>2021-09-23T07:00:00Z</updated><published>2021-09-23T07:00:00Z</published><summary type="html">&lt;p&gt;When deploying applications on &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;, certain platform characteristics strongly influence the application's architecture. In a greenfield setting, it's all about harnessing the ephemeral nature of stateless applications. Applications are built to run in scenarios where there is an expectation of high availability via horizontal scaling. Not only can the application scale out, but Kubernetes' orchestration characteristics emphasize that no individual pod is safe from destruction. Kubernetes is the epitome of the old U.S. Navy Seal saying: "Two is one, and one is none."&lt;/p&gt; &lt;p&gt;Workloads on Kubernetes don't always fit this model, however. Some workloads are singular in nature, and parallelization isn't an option. For example, suppose an application connects out to an external service and receives information asynchronously via a TCP socket or websocket. As part of this process, the application receives data, transforms the structure, and publishes that data into an &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Apache Kafka&lt;/a&gt; topic. In this case, only a single connection can be active at one time because of the possibility of publishing duplicate data (see Figure 1).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="There are two processes, but only one is active at a time." data-entity-type="file" data-entity-uuid="64e0dd2b-3eb5-43b9-92cb-31c66f8ab706" src="https://developers.redhat.com/sites/default/files/inline-images/pic1.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 1: Only one process can be active at a time.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The quick solution to this problem is actually a fundamental characteristic of Kubernetes. If the deployment is created with the &lt;a href="https://docs.openshift.com/container-platform/4.8/applications/deployments/what-deployments-are.html#deployments-kube-deployments_what-deployments-are"&gt;replicas set to 1&lt;/a&gt;, then when the controller detects the pod is no longer running, it will attempt to create a new one. However, real-world situations can be more complicated. Some applications require a long startup time due to cache warming needs. When you combine slow startup times (minutes) for the pod with business requirements to minimize the loss of downtime, the default solution becomes unsuitable. In this situation, we will want to have multiple instances up and ready to take over the consumption as quickly as possible.&lt;/p&gt; &lt;p&gt;This article shows you how to implement leader election in Kubernetes using Apache Camel. To follow along with the examples, see the demo code available on &lt;a href="https://github.com/stephennimmo/quarkus-camel-master-demo"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Hot-warm with leader election&lt;/h2&gt; &lt;p&gt;To run an application as &lt;em&gt;hot-warm&lt;/em&gt; means to have multiple instances of the application running and ready to serve requests, but only one instance actually doing the work. Within Kubernetes, this means having multiple pods ready at all times, but only one pod active for a particular process. In this scenario, the pods negotiate among themselves which one is active.&lt;/p&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/"&gt;Apache Camel&lt;/a&gt; has a component (called &lt;a href="https://camel.apache.org/components/latest/master-component.html"&gt;master&lt;/a&gt;) that is built exactly for this scenario. As the docs explain, the Camel-Master endpoint lets us ensure only a single consumer in a cluster consumes from a given endpoint, with automatic failover if that Java virtual machine (JVM) dies. To achieve this goal, the endpoint requires a shared resource and locking. The component has multiple implementations for the locking mechanism, including the following:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;camel-atomix&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;camel-consul&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;camel-file&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;camel-infinispan&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;camel-jgroups-raft&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;camel-jgroups&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;camel-kubernetes&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;camel-zookeeper&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Within the component's configuration, the developer provides a namespace to designate the shared resource. All processes that use the same namespace for the locking will ensure that only one process at a time obtains the lock. When a process has the lock, it is the leader, and the process will run. If it loses the lock for any reason, the component will stop the process, as well.&lt;/p&gt; &lt;h2&gt;Leader election with a Camel route&lt;/h2&gt; &lt;p&gt;The first example uses the traditional Camel route domain-specific language (DSL), where we incorporate the &lt;a href="https://camel.apache.org/components/latest/master-component.html"&gt;master component&lt;/a&gt; along with the &lt;a href="https://camel.apache.org/components/latest/timer-component.html"&gt;timer component&lt;/a&gt;. For this example, we are using &lt;a href="https://developers.redhat.com/products/quarkus"&gt;Quarkus&lt;/a&gt; and &lt;a href="https://quarkus.io/guides/camel"&gt;Quarkus Camel extensions&lt;/a&gt; to implement the functionality:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java" lang="java" xml:lang="java"&gt;import org.apache.camel.builder.RouteBuilder; import javax.enterprise.context.ApplicationScoped; @ApplicationScoped public class TimerLoggerClusteredRoute extends RouteBuilder { @Override public void configure() throws Exception { from("master:timer-logger-ns:timer://current-leader-check-timer?fixedRate=true&amp;period=500") .log("Current Leader"); } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The first thing you should notice is that the master DSL is prepended to the timer DSL. The DSL designates a namespace of &lt;code&gt;timer-logger-ns&lt;/code&gt;, so all instances of this application will check the locks at regular intervals to see if it's available. However, all the implementation details are obscured from the application as it relates to how the lock is created or managed. It's simply a logical construct around locking a namespace.&lt;/p&gt; &lt;h2&gt;Testing the example locally&lt;/h2&gt; &lt;p&gt;Although we will ultimately deploy this application out to a Kubernetes cluster, we want to demonstrate and test this functionality in our local environment. When doing so, we won't have access to the Kubernetes leases, so we will implement the locking using the &lt;code&gt;camel-file&lt;/code&gt; component. Because of the environmental differences, we will leverage Quarkus &lt;a href="https://quarkus.io/guides/config-reference#profiles"&gt;profiles&lt;/a&gt; to produce the correct &lt;code&gt;CamelClusterService&lt;/code&gt; implementation for our environment:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java" lang="java" xml:lang="java"&gt;@ApplicationScoped public class ClusterLockProducer { @ConfigProperty(name = "namespace") Optional&lt;String&gt; namespace; @Produces @UnlessBuildProfile("prod") public CamelClusterService fileLockClusterService(CamelContext camelContext) throws Exception { FileLockClusterService service = new FileLockClusterService(); service.setRoot("cluster"); service.setAcquireLockDelay(1, TimeUnit.SECONDS); service.setAcquireLockInterval(1, TimeUnit.SECONDS); return service; } @Produces @IfBuildProfile("prod") public CamelClusterService kubernetesClusterService(CamelContext camelContext) { KubernetesClusterService service = new KubernetesClusterService(); if (namespace.isPresent()){ service.setKubernetesNamespace(namespace.get()); } return service; } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For the local environment, we set up the &lt;code&gt;FileLockClusterService&lt;/code&gt;. The &lt;code&gt;setRoot&lt;/code&gt; allows us to designate the location of the files used for the lock, relative or absolute. After the process starts, the files are created and used as locks to designate the current leader, as shown in Figure 2.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="When the process is started with the current configuration in our local development environment, it places the locks into a “cluster” folder setup in the application's working directory." data-entity-type="file" data-entity-uuid="56fb86dd-adde-40d4-a8b9-8a3789c486f6" src="https://developers.redhat.com/sites/default/files/inline-images/pic2.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 2: The target folder that contains the files for locking.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If a new instance of the application is started locally, then the newly started application will not be able to obtain the locks and therefore will not run the timer component. If you kill the leader, the other application will check the lock, see that it's not locked, and subsequently obtain the lock and start processing. Additionally, we can apply settings to designate how often we want the service to check the locks and acquire the lock.&lt;/p&gt; &lt;h2&gt;Leader election without Camel routes&lt;/h2&gt; &lt;p&gt;The Camel route example in the previous section shows how easy it is to add the additional DSL to create and manage singleton processes. However, there are times when the processes to be managed do not fit well into a Camel route, or the processes might already be implemented and we don't necessarily want to have to rewrite the code. Luckily the mechanisms supplied by the master component are available outside of the DSL.&lt;/p&gt; &lt;p&gt;Let's say I have a regular service that can be started and stopped. In this example, the application-scoped bean will instantiate a &lt;a href="https://www.baeldung.com/java-executor-service-tutorial"&gt;single-threaded scheduled executor&lt;/a&gt; that logs messages at a certain fixed rate.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java" lang="java" xml:lang="java"&gt;@ApplicationScoped public class BeanLoggerService { private static final Logger LOGGER = LoggerFactory.getLogger(BeanLoggerService.class); private ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor(); private ScheduledFuture scheduledFuture; public void start() { if (scheduledFuture == null) { scheduledFuture = scheduledExecutorService.scheduleAtFixedRate(() -&gt; { LOGGER.info("{}", System.currentTimeMillis()); }, 1, 1, TimeUnit.SECONDS); } } public void stop() { if (scheduledFuture != null) { this.scheduledFuture.cancel(true); this.scheduledFuture = null; } } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I want to ensure that this service is always running as a singleton among the JVMs. I can accomplish this by obtaining the &lt;code&gt;CamelClusterService&lt;/code&gt; directly and adding an event listener to start and stop the service when leadership changes are detected:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java" lang="java" xml:lang="java"&gt;@Startup public class BeanLoggerLeadershipListener { private static final Logger LOGGER = LoggerFactory.getLogger(BeanLoggerLeadershipListener.class); private CamelContext camelContext; private BeanLoggerService beanLoggerService; public BeanLoggerLeadershipListener(CamelContext camelContext, BeanLoggerService beanLoggerService) { this.camelContext = camelContext; this.beanLoggerService = beanLoggerService; } void onStart(@Observes StartupEvent ev) throws Exception { CamelClusterService camelClusterService = ClusterServiceHelper.lookupService(camelContext).orElseThrow(() -&gt; new RuntimeException("Unable to lookupService for CamelClusterService")); if (camelClusterService instanceof KubernetesClusterService) { KubernetesClusterService kcs = (KubernetesClusterService) camelClusterService; LOGGER.info("KubernetesClusterService: LeaseResourceType={}, KubernetesNamespace={}, KubernetesResourceName={}, MasterUrl={}", kcs.getLeaseResourceType().name(), kcs.getKubernetesNamespace(), kcs.getKubernetesResourceName(), kcs.getMasterUrl()); } camelClusterService.getView("bean-logger-ns").addEventListener((CamelClusterEventListener.Leadership) (view, leader) -&gt; { LOGGER.info("LeadershipEvent[bean-logger-ns]: {}", leader); boolean weAreLeader = leader.isPresent() &amp;&amp; leader.get().isLocal(); if (weAreLeader) { beanLoggerService.start(); } else { beanLoggerService.stop(); } }); } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this example, we are using Quarkus's lifecycle hooks to run code to register the leadership event listener needed to start and stop the &lt;code&gt;BeanLoggerService&lt;/code&gt;. Note that the additional logging code in there will be used to better demonstrate the scenario running in &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Running Camel-Master on OpenShift&lt;/h2&gt; &lt;p&gt;In a local environment, we used the &lt;code&gt;FileLockClusterService&lt;/code&gt;. Now that we are ready to deploy this application on OpenShift, we will switch the implementation from using files to using &lt;a href="https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/lease-v1/"&gt;Kubernetes leases&lt;/a&gt;. To start, let’s take a look at the deployment manifest for the application.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: I used Kustomize to manage all the manifests, so you will notice the absence of the namespace. That's managed in my main &lt;code&gt;kustomization.yaml&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt; &lt;code lang="yaml" xml:lang="yaml"&gt;apiVersion: apps/v1 kind: Deployment metadata: name: quarkus-camel-master-demo-deployment labels: app: quarkus-camel-master-demo spec: replicas: 2 selector: matchLabels: app: quarkus-camel-master-demo template: metadata: labels: app: quarkus-camel-master-demo spec: serviceAccountName: "camel-leader-election" containers: - name: quarkus-camel-master-demo-container image: quay.io/stephennimmo/quarkus-camel-master-demo:0.0.1-SNAPSHOT imagePullPolicy: Always env: - name: QUARKUS_LOG_LEVEL value: "DEBUG" - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace ports: - containerPort: 8080&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this deployment, we have two replicas, but we want only one pod to run the processes. The configuration contains two items of note:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Notice the &lt;code&gt;serviceAccountName&lt;/code&gt; in the deployment config. For this deployment, we need to set up a service account that specifically has access to the &lt;a href="https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/lease-v1/"&gt;Kubernetes leases&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;We are passing in the namespace as a configuration parameter to be used to set up the &lt;code&gt;KubernetesClusterService&lt;/code&gt; to point the same namespace as our application. This will tell the application to attempt to acquire the lease objects in the same namespace as our application.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Before we deploy, we need to set up the service account and give it permissions to read and write to the lease objects:&lt;/p&gt; &lt;pre&gt; &lt;code lang="yaml" xml:lang="yaml"&gt;apiVersion: v1 kind: ServiceAccount metadata: name: camel-leader-election --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: camel-leader-election rules: - apiGroups: -"" - "coordination.k8s.io" resources: - configmaps - secrets - pods - leases verbs: - create - delete - deletecollection - get - list - patch - update - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: camel-leader-election subjects: - kind: ServiceAccount name: camel-leader-election roleRef: kind: Role name: camel-leader-election apiGroup: rbac.authorization.k8s.io&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Leadership elections in OpenShift&lt;/h2&gt; &lt;p&gt;Once we deploy the application into OpenShift, the application will use the &lt;code&gt;KubernetesClusterService&lt;/code&gt; implementation of the &lt;code&gt;CamelClusterService&lt;/code&gt; to perform the leadership elections. To do this, the service will periodically query the lease information and attempt to update the information if the last update has not been performed in the designated lease time. The configuration for the timing of the leader election activity is more detailed, which should be expected; we are no longer simply checking a file lock, but rather working in more of a heartbeat monitoring pattern. Let's take a look at the running pods, the leases, and the associated YAML file.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash" lang="bash" xml:lang="bash"&gt;% oc get pods NAME READY STATUS RESTARTS AGE quarkus-camel-master-demo-deployment-894569d67-fcjhc 1/1 Running 0 4d1h quarkus-camel-master-demo-deployment-894569d67-lt5jv 1/1 Running 0 4d1h % oc get leases NAME HOLDER AGE leaders-bean-logger-ns quarkus-camel-master-demo-deployment-894569d67-lt5jv 15d leaders-timer-logger-ns quarkus-camel-master-demo-deployment-894569d67-fcjhc 18d&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-bash" lang="bash" xml:lang="bash"&gt;% oc get lease leaders-timer-logger-ns -o yaml apiVersion: coordination.k8s.io/v1 kind: Lease metadata: creationTimestamp: "2021-08-08T15:07:29Z" labels: provider: camel managedFields: - apiVersion: coordination.k8s.io/v1 fieldsType: FieldsV1 fieldsV1: f:spec: f:renewTime: {} manager: okhttp operation: Update time: "2021-08-26T15:52:43Z" name: leaders-timer-logger-ns namespace: quarkus-camel-master-demo resourceVersion: "26043451" selfLink: /apis/coordination.k8s.io/v1/namespaces/quarkus-camel-master-demo/leases/leaders-timer-logger-ns uid: 4a79df33-d9d7-4ae1-a16b-d964254f46c6 spec: acquireTime: "2021-08-22T14:23:28.586420Z" holderIdentity: quarkus-camel-master-demo-deployment-894569d67-fcjhc leaseDurationSeconds: 15 leaseTransitions: 20 renewTime: "2021-08-26T15:52:43.467366Z" &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;holderIdentity&lt;/code&gt; shows that the pod named &lt;code&gt;quarkus-camel-master-demo-deployment-894569d67-fcjhc&lt;/code&gt; is currently the leader and is running the timer-logger process. If we look at the logs (Figure 3), we will see that this is the case. We turned on the debugging for the leadership detection so we can actually see the interactions with the leases being updated.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Screenshot of the OpenShift logging view of the pod with the leader election." data-entity-type="file" data-entity-uuid="3199a652-8f5f-4371-9140-e248a87780f8" src="https://developers.redhat.com/sites/default/files/inline-images/pic3.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 3: The OpenShift logging view of the pod with the leader election.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;One of the more interesting pieces to note: This pod is currently only the leader as it relates to the &lt;code&gt;timer-logger-ns&lt;/code&gt;. Remember, we actually have an additional master namespace for the &lt;code&gt;bean-logger-ns&lt;/code&gt;. Let’s take a look at that lease:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash" lang="bash" xml:lang="bash"&gt;% oc get lease leaders-bean-logger-ns -o yaml apiVersion: coordination.k8s.io/v1 kind: Lease metadata: creationTimestamp: "2021-08-10T15:47:54Z" labels: provider: camel managedFields: - apiVersion: coordination.k8s.io/v1 fieldsType: FieldsV1 fieldsV1: f:spec: f:renewTime: {} manager: okhttp operation: Update time: "2021-08-26T16:01:12Z" name: leaders-bean-logger-ns namespace: quarkus-camel-master-demo resourceVersion: "26053368" selfLink: /apis/coordination.k8s.io/v1/namespaces/quarkus-camel-master-demo/leases/leaders-bean-logger-ns uid: faae3687-ea77-45f5-9bad-910c11a21c2b spec: acquireTime: "2021-08-22T14:23:28.424619Z" holderIdentity: quarkus-camel-master-demo-deployment-894569d67-lt5jv leaseDurationSeconds: 15 leaseTransitions: 4 renewTime: "2021-08-26T16:01:12.382697Z" &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For the bean-logging process, the leader is actually the other pod: &lt;code&gt;quarkus-camel-master-demo-deployment-894569d67-lt5jv&lt;/code&gt;. The leadership election for each master namespace is completely independent. This behavior might or might not be suitable for the application's needs, so keep that in mind if you are building multiple dependent processes that need to always run in a single pod.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;To learn more about how Red Hat can support your integration needs, including support for Apache Camel, check out the &lt;a href="https://developers.redhat.com/products/fuse/overview"&gt;Red Hat Fuse&lt;/a&gt; website for more information.&lt;/p&gt; &lt;p&gt;The demo code for this article is available on &lt;a href="https://github.com/stephennimmo/quarkus-camel-master-demo"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Follow me on Twitter &lt;a href="https://twitter.com/stephennimmo"&gt;@stephennimmo&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/23/leader-election-kubernetes-using-apache-camel" title="Leader election in Kubernetes using Apache Camel"&gt;Leader election in Kubernetes using Apache Camel&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ptZfmNY_LdI" height="1" width="1" alt=""/&gt;</summary><dc:creator>Stephen Nimmo</dc:creator><dc:date>2021-09-23T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/23/leader-election-kubernetes-using-apache-camel</feedburner:origLink></entry><entry><title type="html">Visualize, Edit, and Share your BPMN, DMN and PMML with github.dev</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/9Vq3fcx0JNE/visualize-edit-and-share-your-bpmn-dmn-and-pmml-with-github-dev.html" /><author><name>Eder Ignatowicz</name></author><id>https://blog.kie.org/2021/09/visualize-edit-and-share-your-bpmn-dmn-and-pmml-with-github-dev.html</id><updated>2021-09-23T05:00:00Z</updated><content type="html">Some weeks ago, GitHub released which allows you to open any repository in VS Code directly from your browser just pressing . (dot key) on it. On Kogito Tooling 0.13.0 release, we updated our VS Code BPMN, DMN and PMML extension to also work on this innovative environment. Check it out: Note: There is another option to launch github.dev, just replace “.com” on your github URL to “.dev”, as example: HOW TO START TO USE IT? It’s super simple. As soon as you open your “.dev” environment, click on the Extensions menu and search for the BPMN, DMN and PMML extension on VS Code marketplace: COLLABORATE In my opinion, the real power of the github.dev environment is to quickly visualize and collaborate with a project. For instance, you can quickly visually see the differences between your edited model and the version of the current branch: If you are happy with your changes, you can even send a Pull Request directly from github.dev: NEXT STEPS The github.dev is still fresh and new, but I can already see a lot of value for the BPMN and DMN users. As with any experimental feature, there are some issues that we plan to fix on our Editors in the next releases, including: * Resource Content API Support on github.dev, enabling access in a model of other files; * PR visualization doesn’t load all editors side by side on github.dev Stay tuned! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/9Vq3fcx0JNE" height="1" width="1" alt=""/&gt;</content><dc:creator>Eder Ignatowicz</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/visualize-edit-and-share-your-bpmn-dmn-and-pmml-with-github-dev.html</feedburner:origLink></entry><entry><title type="html">WildFly 25 Beta1 S2I images have been released on quay.io</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ScBMUVj3qC4/" /><author><name>Jean-François Denise</name></author><id>https://wildfly.org//news/2021/09/23/WildFly-s2i-25Beta1-Released/</id><updated>2021-09-23T00:00:00Z</updated><content type="html">WILDFLY 25 BETA1 S2I DOCKER IMAGES The WildFly S2I (Source-to-Image) builder and runtime Docker images for WildFly 25 Beta1, have been released on . For complete documentation on how to use these images using S2I, OpenShift and Docker, refer to the WildFly S2I . IMPORTANT CHANGES TO MENTION IN THIS BETA RELEASE We have been evolving the s2i builder image to reflect part of the main changes that occurred in . In particular the s2i image content is impacted by the removal of legacy security: * Changes in the default server configuration: * Now secured with elytron. * Security configuration based on legacy security-realms has been removed. * security subsystem and extension have been removed. * Impact on SSL configuration based on environment variables: * elytron is now used by default to configure SSL. The env variable CONFIGURE_ELYTRON_SSL=true is no more needed. * Impact on Keycloak integration: * By default when configuring Keycloak OIDC and SAML adapters elytron was already in use. Nothing changes there. * If you were using the env variable SSO_FORCE_LEGACY_SECURITY=true to rely on the legacy security subsystem, the server will fail to start, you will need to remove this env variable and rely on elytron integration. ANTICIPATING A FUTURE SUPPORT FOR OPENID CONNECT In this new release we are deprecating the usage of the keycloak Galleon layer and automatic configuration based on We are planning in a future release to rely on the that is providing a native support for OpenID Connect allowing to interact with Keycloak server but with also other servers compatible with the OIDC protocol. Stay tuned!&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ScBMUVj3qC4" height="1" width="1" alt=""/&gt;</content><dc:creator>Jean-François Denise</dc:creator><feedburner:origLink>https://wildfly.org//news/2021/09/23/WildFly-s2i-25Beta1-Released/</feedburner:origLink></entry></feed>
